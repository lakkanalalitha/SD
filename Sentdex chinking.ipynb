{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentdex chinking.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"kZlQ_LbrO6xl","colab_type":"text"},"source":["**Chinking**\n","\n","It is basically a way for you to remove a chunk from a chunk. The chunk that you remove from your chunk is your chink.\n","\n","You may find that, after a lot of chunking, you have some words in your chunk you still do not want, but you have no idea how to get rid of them by chunking. You may find that chinking is your solution."]},{"cell_type":"code","metadata":{"id":"JnoUaS3mOuni","colab_type":"code","colab":{}},"source":["import nltk\n","nltk.download('state_union')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","              \n","from nltk.tokenize import PunktSentenceTokenizer\n","\n","train_text = state_union.raw(\"2005-GWBush.txt\")\n","sample_text = state_union.raw(\"2006-GWBush.txt\")\n","\n","custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n","\n","tokenized = custom_sent_tokenizer.tokenize(sample_text)\n","\n","def process_content():\n","    try:\n","        for i in tokenized[5:]:\n","            words = nltk.word_tokenize(i)\n","            tagged = nltk.pos_tag(words)\n","\n","            chunkGram = r\"\"\"Chunk: {<.*>+}\n","                                    }<VB.?|IN|DT|TO>+{\"\"\"\n","\n","            chunkParser = nltk.RegexpParser(chunkGram)\n","            chunked = chunkParser.parse(tagged)\n","\n","            chunked.draw()\n","\n","    except Exception as e:\n","        print(str(e))\n","\n","process_content()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X_0kJCRBQAu-","colab_type":"text"},"source":["The code is very similar, you just denote the chink, after the chunk, with }{ instead of the chunk's {}."]}]}