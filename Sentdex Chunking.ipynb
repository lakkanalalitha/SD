{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chunking.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"al_C2sREHTUB","colab_type":"text"},"source":["https://pythonprogramming.net/chunking-nltk-tutorial/?completed=/part-of-speech-tagging-nltk-tutorial/\n","\n","**Chunking**\n","\n","Chunking is a process of extracting phrases from unstructured text.  Instead of just simple tokens which may not represent the actual meaning of the text, its advisable to use phrases such as \n","\n","**“South Africa”** as a single word instead of ‘**South**’ and ‘**Africa**’ separate words.\n","\n","Chunking works on top of POS tagging, it uses pos-tags as input and provides chunks as output. \n","\n","A grouping of the words in “chunks”\n","\n","**Bag-of-words fails **to capture the \n","\n","1) structure of the sentences \n","\n","2) giving its appropriate meaning.\n","\n","POS and Chunking helps us overcome this weakness.\n","\n","**Named Entity Extraction**\n","\n"," Chunking is very important when you want to extract information from text such as Locations, Person Names etc. In NLP called Named Entity Extraction."]},{"cell_type":"markdown","metadata":{"id":"nwJ4hyt7K42v","colab_type":"text"},"source":["In order to chunk, we combine the part of speech tags with regular expressions.\n","\n"]},{"cell_type":"code","metadata":{"id":"8szEaxm6K6mW","colab_type":"code","colab":{}},"source":["'''\n","+ = match 1 or more\n","? = match 0 or 1 repetitions.\n","* = match 0 or MORE repetitions\t  \n",". = Any character except a new line\n","'''\n","\n","#Define your grammar using regular expressions\n","chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u6fgDZ2pLkW9","colab_type":"code","colab":{}},"source":["import nltk\n","from nltk.corpus import state_union\n","from nltk.tokenize import PunktSentenceTokenizer\n","nltk.download('state_union')\n","  \n","\n","train_text = state_union.raw(\"2005-GWBush.txt\")\n","sample_text = state_union.raw(\"2006-GWBush.txt\")\n","\n","custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n","\n","tokenized = custom_sent_tokenizer.tokenize(sample_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7VJFnpRLxyt","colab_type":"code","colab":{}},"source":["nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","\n","#Define your grammar using regular expressions\n","chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n","\n","def process_content():\n","    try:\n","        for i in tokenized:\n","            words = nltk.word_tokenize(i)\n","            tagged = nltk.pos_tag(words)\n","            chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n","            chunkParser = nltk.RegexpParser(chunkGram)\n","            chunked = chunkParser.parse(tagged)\n","            chunked.draw()     \n","\n","    except Exception as e:\n","        print(str(e))\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ybfek89NMS-1","colab_type":"code","colab":{}},"source":["process_content()"],"execution_count":0,"outputs":[]}]}